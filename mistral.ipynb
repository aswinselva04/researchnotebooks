{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d83f7-c2f7-4635-a056-5a56074ef339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c07fa4-8513-42cc-82f2-cc0ab9ce7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d092fea-d96d-4546-ba96-242b3a529cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e0e388-48b6-4333-a91f-a8993ed8d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "llm.invoke(\"Tell me another joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c14e79-5038-4d05-b26e-c30a9be5c28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04768fe1-4736-4f07-9e7e-becb6c317b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True, device_map='mps')\n",
    "\n",
    "# text = \"Hello my name is\"\n",
    "# inputs = tokenizer(text, return_tensors=\"pt\").to(\"mps\")\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb52824a-25db-46de-9ca5-01388fb78c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a18ba8d4-a547-4036-b28e-ef1a65de8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit = True,\n",
    "#     bnb_4bit_use_double_quant = True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "# model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b5af2b-4d09-4119-afb2-10bab57311af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf40b38-63e3-4bfd-b221-e333fbcd2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e07fbfd-718d-4256-89cc-efaa1f2a2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import qdrant_client\n",
    "# from llama_index import VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
    "# from llama_index.llms import Ollama\n",
    "# from llama_index.storage.storage_context import StorageContext\n",
    "# from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "# # Loading the documents from the disk\n",
    "# documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "# # Initializing the vector store with Qdrant\n",
    "# client = qdrant_client.QdrantClient(path=\"./qdrant_data\")\n",
    "# vector_store = QdrantVectorStore(client=client, collection_name=\"springboot\")\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# # Initializing the Large Language Model (LLM) with Ollama\n",
    "# # The request_timeout may need to be adjusted depending on the system's performance capabilities\n",
    "# llm = Ollama(model=\"mistral\", request_timeout=120.0)\n",
    "# service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")\n",
    "\n",
    "# # Creating the index, which includes embedding the documents into the vector store\n",
    "# index = VectorStoreIndex.from_documents(documents, service_context=service_context, storage_context=storage_context)\n",
    "\n",
    "# # Querying the index with a specific question\n",
    "# query_engine = index.as_query_engine()\n",
    "# prompt = (\n",
    "#   \"What are the optimization methods, show me only the method name\"\n",
    "# )\n",
    "# response = query_engine.query(prompt)\n",
    "# client.close()\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30dd8c66-10fa-47d4-bfcd-9445d46ba47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72cfbdce-b731-4022-82f7-e7adda29c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LEGO is a Danish toy company that produces interlocking plastic bricks and other construction toys. The company was founded on August 10, 1932 by Ole Kirk Christiansen in Billund, Denmark. Initially, the company produced wooden toys, but during the late 1940s, they began manufacturing the first LEGO bricks using a plastic resin.\n",
      "\n",
      "The name \"LEGO\" is derived from the Danish words \"leg godt,\" which mean \"play well.\" The interlocking bricks were first introduced in 1949 and were initially marketed under the name \"Automatic Binding Bricks.\" However, the brand name LEGO did not officially appear until 1954.\n",
      "\n",
      "In the 1960s, the company introduced various themes for its sets, including space exploration, castles, and towns. In 1968, they released their most famous set to date: the LEGO Modular House. This modular system allowed children to build houses with multiple rooms and stories by connecting pre-designed modules together.\n",
      "\n",
      "Throughout the 1970s and 1980s, LEGO continued to expand its product line, introducing new themes such as pirates, knights, and spacemen. In 1995, the company launched its System in Play theme, which encouraged children to mix and match bricks from various themes to create their own unique creations.\n",
      "\n",
      "In the late 1990s and early 2000s, LEGO underwent significant financial difficulties due to increased competition from other toy companies and poor management decisions. However, a new leadership team took over in 2004, and they began implementing strategies to revitalize the brand. This included partnering with popular franchises such as Star Wars, Harry Potter, and Indiana Jones to create licensed sets based on these properties.\n",
      "\n",
      "Today, LEGO is one of the most successful toy companies in the world, with a global presence and a wide range of products that cater to children of all ages. The company continues to innovate and expand its product offerings, including robotics kits, educational sets, and even adult-focused builds.\n"
     ]
    }
   ],
   "source": [
    "# Just runs .complete to make sure the LLM is listening\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "response = llm.complete(\"What is the history of LEGO?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "593f853c-f099-4c03-834b-aa78d95c29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f70a2914-a3df-4f7b-9589-d3f27a7afa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9371866-f977-4ff7-9173-27914549ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "741f98de-10ec-40cb-a467-57a0dc1288b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase, ServiceContext\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\n",
    "        \"city_name\": \"Chicago\",\n",
    "        \"population\": 2679000,\n",
    "        \"country\": \"United States\",\n",
    "    },\n",
    "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3911f2a2-fedf-4392-8518-5449e586dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/n9s1wd956zs2c_l90d4zk39w0000gn/T/ipykernel_1281/2299164370.py:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm,  embed_model=\"local\")\n",
      "/Users/aswin/miniconda3/envs/mlenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████████████████████████| 684/684 [00:00<00:00, 245kB/s]\n",
      "model.safetensors: 100%|█████████████████████| 133M/133M [00:16<00:00, 7.88MB/s]\n",
      "tokenizer_config.json: 100%|████████████████████| 366/366 [00:00<00:00, 105kB/s]\n",
      "vocab.txt: 100%|██████████████████████████████| 232k/232k [00:00<00:00, 586kB/s]\n",
      "tokenizer.json: 100%|█████████████████████████| 711k/711k [00:00<00:00, 813kB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 125/125 [00:00<00:00, 39.2kB/s]\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"mistral\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm,  embed_model=\"local\")\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dc23ca0-d7d3-4fc1-bf04-2fa497cfbf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Chicago', 2679000, 'United States'), ('Seoul', 9776000, 'South Korea')]\n"
     ]
    }
   ],
   "source": [
    "stmt = select(\n",
    "    city_stats_table.c.city_name,\n",
    "    city_stats_table.c.population,\n",
    "    city_stats_table.c.country,\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "914a0012-7658-43a2-b18a-c6728311630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chicago',)\n",
      "('Seoul',)\n",
      "('Tokyo',)\n",
      "('Toronto',)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38bad644-5b02-42bc-b3a2-db624d9b43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"city_stats\"],\n",
    "    service_context = service_context\n",
    ")\n",
    "query_str = \"Which city has the highest population?\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "760eec98-1258-4104-9dec-c2765ed324a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' Based on the input question and assuming we have a table named \"city\\\\_stats\" with columns \"city\\\\_name\" and \"population,\" the correct SQL query would be as follows:\\n\\nSQL: SELECT city\\\\_name FROM city\\\\_stats ORDER BY population DESC LIMIT 1;\\n\\nResponse: The city with the highest population is [City Name] (assuming the first record returned from the query).', source_nodes=[NodeWithScore(node=TextNode(id_='87f50e35-ee10-4976-85cd-78ee3973dec0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"Error: Statement 'SELECT city\\\\\\\\_name, population FROM city\\\\\\\\_stats ORDER BY population DESC LIMIT 1;' is invalid SQL.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'87f50e35-ee10-4976-85cd-78ee3973dec0': {}, 'sql_query': 'SELECT city\\\\_name, population FROM city\\\\_stats ORDER BY population DESC LIMIT 1;'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e39e1afd-68ec-4c0a-9912-8cabe3406c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b> I'm sorry for the confusion earlier. The given SQL query seems to be incorrect as there is no table named \"city\\_stats\" specified in the query. Here is a corrected version of the SQL query assuming we have a table named \"population\\_data\" with columns \"city\\_name\" and \"population\":\n",
       "\n",
       "SQL: SELECT city\\_name FROM population\\_data ORDER BY population DESC LIMIT 1;\n",
       "\n",
       "Response: The city with the highest population is [City Name], according to the query results. (Replace \"[City Name]\" with the actual name of the city from the SQL response.)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\"))\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    "    service_context = service_context\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=5),\n",
    "    service_context = service_context\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which city has the highest population?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f548fbd-e3fc-4d06-8f6f-8a99c38d52c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT city_name, population FROM city_stats ORDER BY population DESC LIMIT 1;'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata['sql_query'].replace('\\\\', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fddd0da-1c0f-4401-857d-1c7efbc2466f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 17db383a-f008-4e1e-9f19-f7fda59a2c67<br>**Similarity:** None<br>**Text:** [('Tokyo', 13960000), ('Seoul', 9776000), ('Toronto', 2930000), ('Chicago', 2679000)]<br>**Metadata:** {}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.retrievers import NLSQLRetriever\n",
    "\n",
    "# default retrieval (return_raw=True)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"city_stats\"], return_raw=True,\n",
    "    service_context = service_context  \n",
    ")\n",
    "\n",
    "results = nl_sql_retriever.retrieve(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_source_node\n",
    "for n in results:\n",
    "    display_source_node(n, show_source_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad0d76-2ce8-4912-9077-72e0e5946333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "597d983a-ba8a-416b-8208-17138511ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlvalidator\n",
    "\n",
    "sql_query = sqlvalidator.parse(response.metadata['sql_query'])\n",
    "\n",
    "if not sql_query.is_valid():\n",
    "    print(sql_query.errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da1b9463-3292-4da8-8137-5c8ed24c54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever, service_context=service_context)\n",
    "response = query_engine.query(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c8fe291-9e68-48c6-b82d-caa39641ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To retrieve the top 5 cities with the highest population, you can use a SQL query in the following format:\n",
      "```sql\n",
      "SELECT city_name, population \n",
      "FROM city_stats \n",
      "ORDER BY population DESC \n",
      "LIMIT 5;\n",
      "```\n",
      "However, based on the context provided, it seems that there is an error in the syntax of the query. To correct this error, make sure to include a semicolon at the end of the statement:\n",
      "```sql\n",
      "SELECT city_name, population \n",
      "FROM city_stats \n",
      "ORDER BY population DESC \n",
      "LIMIT 5;\n",
      "```\n",
      "This corrected query will return the top 5 cities with the highest population from the `city_stats` table.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2220c-4177-4293-b73a-39a61fd0b4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
