{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c07fa4-8513-42cc-82f2-cc0ab9ce7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d092fea-d96d-4546-ba96-242b3a529cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e0e388-48b6-4333-a91f-a8993ed8d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Why don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\\nOr, if you prefer a classic:\\n\\nWhy did the chicken cross the playground?\\n\\nTo get to the other slide!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "llm.invoke(\"Tell me another joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c14e79-5038-4d05-b26e-c30a9be5c28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04768fe1-4736-4f07-9e7e-becb6c317b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True, device_map='mps')\n",
    "\n",
    "# text = \"Hello my name is\"\n",
    "# inputs = tokenizer(text, return_tensors=\"pt\").to(\"mps\")\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb52824a-25db-46de-9ca5-01388fb78c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a18ba8d4-a547-4036-b28e-ef1a65de8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit = True,\n",
    "#     bnb_4bit_use_double_quant = True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "# model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b5af2b-4d09-4119-afb2-10bab57311af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf40b38-63e3-4bfd-b221-e333fbcd2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e07fbfd-718d-4256-89cc-efaa1f2a2306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I cannot directly provide a list of optimization methods from the context information as it does not mention any specific optimization methods aside from early stopping which is actually a regularization technique rather than an optimization method itself.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import qdrant_client\n",
    "from llama_index import VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
    "from llama_index.llms import Ollama\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "# Loading the documents from the disk\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "# Initializing the vector store with Qdrant\n",
    "client = qdrant_client.QdrantClient(path=\"./qdrant_data\")\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"springboot\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Initializing the Large Language Model (LLM) with Ollama\n",
    "# The request_timeout may need to be adjusted depending on the system's performance capabilities\n",
    "llm = Ollama(model=\"mistral\", request_timeout=120.0)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")\n",
    "\n",
    "# Creating the index, which includes embedding the documents into the vector store\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context, storage_context=storage_context)\n",
    "\n",
    "# Querying the index with a specific question\n",
    "query_engine = index.as_query_engine()\n",
    "prompt = (\n",
    "  \"What are the optimization methods, show me only the method name\"\n",
    ")\n",
    "response = query_engine.query(prompt)\n",
    "client.close()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30dd8c66-10fa-47d4-bfcd-9445d46ba47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72cfbdce-b731-4022-82f7-e7adda29c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LEGO is a Danish toy manufacturing company that produces interlocking brick system toys. The company was founded on August 10, 1932, by Ole Kirk Christiansen in Billund, Denmark. Originally named \"Leg Godt,\" which means \"Play Well\" in Danish, the company started producing wooden toys.\n",
      "\n",
      "In 1947, Christiansen acquired a small factory that was producing plastic toys, and he began experimenting with plastic injection molding. In 1949, he produced the first LEGO bricks, which were made from a strong, durable plastic called acrylonitrile butadiene styrene (ABS). The bricks were designed to interlock, allowing for easy construction of various structures and models.\n",
      "\n",
      "The first LEGO sets were marketed towards children and were sold in Europe. In the 1950s, Christiansen started producing more complex sets that included figures and accessories. In the late 1950s, the company introduced the iconic LEGO minifigure, which has remained a staple of LEGO sets to this day.\n",
      "\n",
      "Throughout the 1960s and 1970s, LEGO continued to expand its product line, introducing new themes and models. In the late 1970s, the company experienced financial difficulties due to competition from other toy companies and a change in consumer trends away from traditional toys towards electronics.\n",
      "\n",
      "In the early 1980s, the company was bought by the Kirkbi Foundation, which is still the majority owner today. Under new management, LEGO started producing more complex and sophisticated sets that appealed to older builders, and in the late 1990s, the company began licensing its products for use in video games and movies, leading to a resurgence in popularity.\n",
      "\n",
      "Today, LEGO is one of the world's most recognizable toy brands, with a vast product line that includes sets for all ages, from young children to adult enthusiasts. The company has also expanded beyond toys, producing a range of other products including software, games, and even theme parks.\n"
     ]
    }
   ],
   "source": [
    "# Just runs .complete to make sure the LLM is listening\n",
    "from llama_index.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "response = llm.complete(\"What is the history of LEGO?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "593f853c-f099-4c03-834b-aa78d95c29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f70a2914-a3df-4f7b-9589-d3f27a7afa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9371866-f977-4ff7-9173-27914549ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "741f98de-10ec-40cb-a467-57a0dc1288b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SQLDatabase, ServiceContext\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\n",
    "        \"city_name\": \"Chicago\",\n",
    "        \"population\": 2679000,\n",
    "        \"country\": \"United States\",\n",
    "    },\n",
    "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3911f2a2-fedf-4392-8518-5449e586dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"mistral\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm,  embed_model=\"local\")\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dc23ca0-d7d3-4fc1-bf04-2fa497cfbf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Chicago', 2679000, 'United States'), ('Seoul', 9776000, 'South Korea')]\n"
     ]
    }
   ],
   "source": [
    "stmt = select(\n",
    "    city_stats_table.c.city_name,\n",
    "    city_stats_table.c.population,\n",
    "    city_stats_table.c.country,\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "914a0012-7658-43a2-b18a-c6728311630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chicago',)\n",
      "('Seoul',)\n",
      "('Tokyo',)\n",
      "('Toronto',)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38bad644-5b02-42bc-b3a2-db624d9b43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"city_stats\"],\n",
    "    service_context = service_context\n",
    ")\n",
    "query_str = \"Which city has the highest population?\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "760eec98-1258-4104-9dec-c2765ed324a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' Based on the query results, Tokyo is the city with the highest population. Therefore, the response to the question \"Which city has the highest population?\" would be:\\n\\n\"The city with the highest population is Tokyo, with a population of approximately 13,960,000 people.\"', source_nodes=[NodeWithScore(node=TextNode(id_='1faf40ab-8691-4f0d-87e6-072049b3689e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"[('Tokyo', 13960000)]\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'1faf40ab-8691-4f0d-87e6-072049b3689e': {}, 'sql_query': 'SELECT city_name, population FROM city_stats ORDER BY population DESC LIMIT 1;', 'result': [('Tokyo', 13960000)], 'col_keys': ['city_name', 'population']})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e39e1afd-68ec-4c0a-9912-8cabe3406c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b> Based on the query results, Tokyo is the city with the highest population, with a population of approximately 13,960,000 people.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\"))\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    "    service_context = service_context\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=5),\n",
    "    service_context = service_context\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which city has the highest population?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f548fbd-e3fc-4d06-8f6f-8a99c38d52c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT city_name, population FROM city_stats ORDER BY population DESC LIMIT 1;'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata['sql_query']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fddd0da-1c0f-4401-857d-1c7efbc2466f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 17db383a-f008-4e1e-9f19-f7fda59a2c67<br>**Similarity:** None<br>**Text:** [('Tokyo', 13960000), ('Seoul', 9776000), ('Toronto', 2930000), ('Chicago', 2679000)]<br>**Metadata:** {}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.retrievers import NLSQLRetriever\n",
    "\n",
    "# default retrieval (return_raw=True)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"city_stats\"], return_raw=True,\n",
    "    service_context = service_context  \n",
    ")\n",
    "\n",
    "results = nl_sql_retriever.retrieve(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_source_node\n",
    "for n in results:\n",
    "    display_source_node(n, show_source_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da1b9463-3292-4da8-8137-5c8ed24c54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever, service_context=service_context)\n",
    "response = query_engine.query(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c8fe291-9e68-48c6-b82d-caa39641ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To retrieve the top 5 cities with the highest population, you can use a SQL query in the following format:\n",
      "```sql\n",
      "SELECT city_name, population \n",
      "FROM city_stats \n",
      "ORDER BY population DESC \n",
      "LIMIT 5;\n",
      "```\n",
      "However, based on the context provided, it seems that there is an error in the syntax of the query. To correct this error, make sure to include a semicolon at the end of the statement:\n",
      "```sql\n",
      "SELECT city_name, population \n",
      "FROM city_stats \n",
      "ORDER BY population DESC \n",
      "LIMIT 5;\n",
      "```\n",
      "This corrected query will return the top 5 cities with the highest population from the `city_stats` table.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2220c-4177-4293-b73a-39a61fd0b4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
